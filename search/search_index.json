{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"","title":"Home"},{"location":"getting-started.html","text":"Getting Started \u00b6","title":"Getting Started"},{"location":"getting-started.html#getting-started","text":"","title":"Getting Started"},{"location":"Integrations/index.html","text":"","title":"Index"},{"location":"Integrations/Datadog.html","text":"Datadog Integration \u00b6 Komodor-Datadog integration allows you to see service connections in Komodor. Services that are detected as related by Datadog will be added to the Related Services section in the Komodor Services View. Installation \u00b6 Prerequisites \u00b6 In order for us to connect your services according to Datadog tracing, the following environment variables should exist on your kubernetes deployments: - DD_ENV should match the environment specified on the Datadog service - DD_SERVICE should match the service name specified on the Datadog service Installation Steps \u00b6 Make sure the above prerequisites are met. Locate the Datadog installation tile on Komodor Integrations page. Press Install Integration . Follow the on screen instructions. Confirmation \u00b6 A Datadog Integration tile will be added to the top section under Installed Integrations . Your services that interact with each other will appear under the Related Services section in the Komodor services page.","title":"Datadog"},{"location":"Integrations/Datadog.html#datadog-integration","text":"Komodor-Datadog integration allows you to see service connections in Komodor. Services that are detected as related by Datadog will be added to the Related Services section in the Komodor Services View.","title":"Datadog Integration"},{"location":"Integrations/Datadog.html#installation","text":"","title":"Installation"},{"location":"Integrations/Datadog.html#prerequisites","text":"In order for us to connect your services according to Datadog tracing, the following environment variables should exist on your kubernetes deployments: - DD_ENV should match the environment specified on the Datadog service - DD_SERVICE should match the service name specified on the Datadog service","title":"Prerequisites"},{"location":"Integrations/Datadog.html#installation-steps","text":"Make sure the above prerequisites are met. Locate the Datadog installation tile on Komodor Integrations page. Press Install Integration . Follow the on screen instructions.","title":"Installation Steps"},{"location":"Integrations/Datadog.html#confirmation","text":"A Datadog Integration tile will be added to the top section under Installed Integrations . Your services that interact with each other will appear under the Related Services section in the Komodor services page.","title":"Confirmation"},{"location":"Integrations/Grafana.html","text":"Grafana Integration \u00b6 Grafana Integration adds Grafana Alert events to your service in Komodor. Installation \u00b6 Prerequisites \u00b6 A running instance of Grafana. Installation Steps \u00b6 Make sure the above prerequisites are met. Locate the Grafana installation tile on the Komodor Integrations page. Press Install Integration . A dialog will open. Go to your Grafana instance. In the Grafana side bar, hover your cursor over the Alerting (bell) icon and then click Notification channels . Press New channel . In the Name field, enter a name for the channel. In the Type field, choose webhook . Copy the webhook URL to the Url field. Open the Notifications settings . Check the Default option. When selected, this option sends a notification on this channel for all alert rules. Press Save Press Install Grafana Installation Confirmation \u00b6 A Grafana Integration tile will be added to the top section under Installed Integrations . When a Grafana alert is triggered it will be added to the relevant service in Komodor.","title":"Grafana"},{"location":"Integrations/Grafana.html#grafana-integration","text":"Grafana Integration adds Grafana Alert events to your service in Komodor.","title":"Grafana Integration"},{"location":"Integrations/Grafana.html#installation","text":"","title":"Installation"},{"location":"Integrations/Grafana.html#prerequisites","text":"A running instance of Grafana.","title":"Prerequisites"},{"location":"Integrations/Grafana.html#installation-steps","text":"Make sure the above prerequisites are met. Locate the Grafana installation tile on the Komodor Integrations page. Press Install Integration . A dialog will open. Go to your Grafana instance. In the Grafana side bar, hover your cursor over the Alerting (bell) icon and then click Notification channels . Press New channel . In the Name field, enter a name for the channel. In the Type field, choose webhook . Copy the webhook URL to the Url field. Open the Notifications settings . Check the Default option. When selected, this option sends a notification on this channel for all alert rules. Press Save Press Install Grafana Installation","title":"Installation Steps"},{"location":"Integrations/Grafana.html#confirmation","text":"A Grafana Integration tile will be added to the top section under Installed Integrations . When a Grafana alert is triggered it will be added to the relevant service in Komodor.","title":"Confirmation"},{"location":"Integrations/LaunchDarkly.html","text":"LaunchDarkly Integration \u00b6 Integration with LaunchDarkly extends the holistic view of the environment with flag changes. For example: Feature flag was turned on Feature flag in variation changed Feature flag targeting was changed Installation \u00b6 In order to create the integration navigate to LaunchDarkly Webhook Integration and fill the form: Name - give your integration a name. URL - Please contact us to provide you the URL (we also will provide you a secret to sign the webhooks payload). Sign Webhook - use the secret from Komodor. Add policy You can use the following statement to tell LaunchDarkly to send to Komodor all the changes for all your flags across all your environments. You may use the \"Resource finder\" to customize it for your needs. commandline proj/*:env/*:flag/* Set the effect to \"Allow\" Choose all actions Click \"Update\" Check \"I have read and agree to the Integration Terms and Conditions\" Click \"Save Changes\" to finish the integration.","title":"LaunchDarkly"},{"location":"Integrations/LaunchDarkly.html#launchdarkly-integration","text":"Integration with LaunchDarkly extends the holistic view of the environment with flag changes. For example: Feature flag was turned on Feature flag in variation changed Feature flag targeting was changed","title":"LaunchDarkly Integration"},{"location":"Integrations/LaunchDarkly.html#installation","text":"In order to create the integration navigate to LaunchDarkly Webhook Integration and fill the form: Name - give your integration a name. URL - Please contact us to provide you the URL (we also will provide you a secret to sign the webhooks payload). Sign Webhook - use the secret from Komodor. Add policy You can use the following statement to tell LaunchDarkly to send to Komodor all the changes for all your flags across all your environments. You may use the \"Resource finder\" to customize it for your needs. commandline proj/*:env/*:flag/* Set the effect to \"Allow\" Choose all actions Click \"Update\" Check \"I have read and agree to the Integration Terms and Conditions\" Click \"Save Changes\" to finish the integration.","title":"Installation"},{"location":"Integrations/MicrosoftTeams.html","text":"Microsoft Teams Integration \u00b6 The Teams integration allows configuration of notifications for events such as Deploy or Health from Komodor to a Teams channel. Komodor supports different granularity levels, Cluster, Namespace and Service for each notification. The notification type, destination, and granularity can be defined in the Komodor Notifications screen. Configuring Teams Notifications \u00b6 Configuration Steps \u00b6 Open up the Komodor Notifications Panel . On this screen you can see all existing notifications or configure new ones. Scroll to the bottom of the page and decide which type of notification you would like to create, Deployment or Health Change. Select Add this notification for the type of notification you would like to configure. Choose the cluster that you would like to alert on, or leave empty to alert on all clusters. Click Continue to proceed to the webhook configuration. Enter the channel name that you would like to post to (starting with @. \"@channel\" for example) Retrieve the webhook URL from Teams using the on screen instructions: Navigate to the channel where you want to add the webhook and select (\u2022\u2022\u2022) More Options from the top navigation bar. Choose Connectors from the drop-down menu and search for Incoming Webhook. Select the Configure button, provide a name, and optionally, upload an image avatar for your webhook. The dialog window will present a unique URL that will map to the channel. Make sure that you copy and paste the URL into the \"webhook URL\" field. Click on Create Notification to complete the Notification Configuration More information on Microsoft Teams integration with webhooks can be found in the Official Documentation .","title":"Microsoft Teams"},{"location":"Integrations/MicrosoftTeams.html#microsoft-teams-integration","text":"The Teams integration allows configuration of notifications for events such as Deploy or Health from Komodor to a Teams channel. Komodor supports different granularity levels, Cluster, Namespace and Service for each notification. The notification type, destination, and granularity can be defined in the Komodor Notifications screen.","title":"Microsoft Teams Integration"},{"location":"Integrations/MicrosoftTeams.html#configuring-teams-notifications","text":"","title":"Configuring Teams Notifications"},{"location":"Integrations/MicrosoftTeams.html#configuration-steps","text":"Open up the Komodor Notifications Panel . On this screen you can see all existing notifications or configure new ones. Scroll to the bottom of the page and decide which type of notification you would like to create, Deployment or Health Change. Select Add this notification for the type of notification you would like to configure. Choose the cluster that you would like to alert on, or leave empty to alert on all clusters. Click Continue to proceed to the webhook configuration. Enter the channel name that you would like to post to (starting with @. \"@channel\" for example) Retrieve the webhook URL from Teams using the on screen instructions: Navigate to the channel where you want to add the webhook and select (\u2022\u2022\u2022) More Options from the top navigation bar. Choose Connectors from the drop-down menu and search for Incoming Webhook. Select the Configure button, provide a name, and optionally, upload an image avatar for your webhook. The dialog window will present a unique URL that will map to the channel. Make sure that you copy and paste the URL into the \"webhook URL\" field. Click on Create Notification to complete the Notification Configuration More information on Microsoft Teams integration with webhooks can be found in the Official Documentation .","title":"Configuration Steps"},{"location":"Integrations/PagerDuty.html","text":"PagerDuty Integration \u00b6 PagerDuty Integration adds PagerDuty Incident events to your services events. NOTE: We currently only support PD events that originate in Datadog. Installation \u00b6 Prerequisites \u00b6 In order to connect your Datadog-PD incidents to your services in Komodor, you need to match environment variables found in Datadog to your services in Kubernetes. Please make sure the following environment variables exist in your kubernetes deployment: - DD_ENV should match the environment specified on the Datadog service - DD_SERVICE should match the service name specified on the Datadog service Installation Steps \u00b6 Make sure the prerequisites above are met. Locate the PagerDuty installation tile on Komodor Integrations page. Press Install Integration . You will be redirected to Pagerduty and back to Komodor successfully. Confirmation \u00b6 A PagerDuty Integration tile will be added to the top section of labeled Installed Integrations . When an issue from Datadog is raised through PD, you will be able to find it in the appropriate Komodor services page.","title":"PagerDuty"},{"location":"Integrations/PagerDuty.html#pagerduty-integration","text":"PagerDuty Integration adds PagerDuty Incident events to your services events. NOTE: We currently only support PD events that originate in Datadog.","title":"PagerDuty Integration"},{"location":"Integrations/PagerDuty.html#installation","text":"","title":"Installation"},{"location":"Integrations/PagerDuty.html#prerequisites","text":"In order to connect your Datadog-PD incidents to your services in Komodor, you need to match environment variables found in Datadog to your services in Kubernetes. Please make sure the following environment variables exist in your kubernetes deployment: - DD_ENV should match the environment specified on the Datadog service - DD_SERVICE should match the service name specified on the Datadog service","title":"Prerequisites"},{"location":"Integrations/PagerDuty.html#installation-steps","text":"Make sure the prerequisites above are met. Locate the PagerDuty installation tile on Komodor Integrations page. Press Install Integration . You will be redirected to Pagerduty and back to Komodor successfully.","title":"Installation Steps"},{"location":"Integrations/PagerDuty.html#confirmation","text":"A PagerDuty Integration tile will be added to the top section of labeled Installed Integrations . When an issue from Datadog is raised through PD, you will be able to find it in the appropriate Komodor services page.","title":"Confirmation"},{"location":"Integrations/Sentry.html","text":"Sentry Integration \u00b6 The Sentry integration allows you to see sentry issues in Komodor. For each service, Komodor automatically maps the relevant Sentry project to Komodor services and allows you to gain a full-service timeline: both relevant changes (deploys, config changes etc\u2019) and issues from Sentry will all be in one place. Installation \u00b6 Installation Steps \u00b6 Make sure the services you track in Komodor use the SENTRY_DSN environment variable. Locate the Sentry installation tile on the Komodor Integrations page. Click Install Integration . A dialog will open with a webhook URL and a link to Sentry to define an internal integration. Go to your Sentry account and click on settings in the left menu. Click on Developer Settings in the settings menu: Click on + New Internal Integration Name this integration Komodor. Paste the webhook URL in the webhook field: To operate properly Komodor needs these permissions: Project - Read Issue & Event - Read Check the issue webhook checkbox Save changes As soon as you save you will see your \u201cclient secret\u201d. Copy the value: Go back to your Komodor integrations page and paste the value of your client secret to the client secret text box. Click Install In your deployment.yaml \u00b6 We use the value of the environment variable SENTRY_DSN to match Sentry Issue events with your services in Komodor. Make sure your kubernetes deployment has the environment variable SENTRY_DSN . Confirmation \u00b6 A Sentry Integration tile will be added to the top section under Installed Integrations . Once completed you will be able to see Sentry events in you services view:","title":"Sentry"},{"location":"Integrations/Sentry.html#sentry-integration","text":"The Sentry integration allows you to see sentry issues in Komodor. For each service, Komodor automatically maps the relevant Sentry project to Komodor services and allows you to gain a full-service timeline: both relevant changes (deploys, config changes etc\u2019) and issues from Sentry will all be in one place.","title":"Sentry Integration"},{"location":"Integrations/Sentry.html#installation","text":"","title":"Installation"},{"location":"Integrations/Sentry.html#installation-steps","text":"Make sure the services you track in Komodor use the SENTRY_DSN environment variable. Locate the Sentry installation tile on the Komodor Integrations page. Click Install Integration . A dialog will open with a webhook URL and a link to Sentry to define an internal integration. Go to your Sentry account and click on settings in the left menu. Click on Developer Settings in the settings menu: Click on + New Internal Integration Name this integration Komodor. Paste the webhook URL in the webhook field: To operate properly Komodor needs these permissions: Project - Read Issue & Event - Read Check the issue webhook checkbox Save changes As soon as you save you will see your \u201cclient secret\u201d. Copy the value: Go back to your Komodor integrations page and paste the value of your client secret to the client secret text box. Click Install","title":"Installation Steps"},{"location":"Integrations/Sentry.html#in-your-deploymentyaml","text":"We use the value of the environment variable SENTRY_DSN to match Sentry Issue events with your services in Komodor. Make sure your kubernetes deployment has the environment variable SENTRY_DSN .","title":"In your deployment.yaml"},{"location":"Integrations/Sentry.html#confirmation","text":"A Sentry Integration tile will be added to the top section under Installed Integrations . Once completed you will be able to see Sentry events in you services view:","title":"Confirmation"},{"location":"Integrations/datadog-webhook.html","text":"Datadog Webhook Integration \u00b6 Komodor-Datadog webhook integration allows Komodor to receive alerts from Datadog Monitors. You will see all alerts in the Komodor Service View. Installation \u00b6 Prerequisites \u00b6 In order for us to connect your services according to Datadog events, the following environment variables should exist on your kubernetes deployments: - DD_ENV should match the environment specified on the Datadog tags - DD_SERVICE should match the service name specified on the Datadog tags Installation Steps \u00b6 Make sure the prerequisites above are met. Locate the Datadog installation tile on Komodor Integrations page. Press Install Integration . Follow the on screen instructions. Confirmation \u00b6 A Datadog Integration tile will be added to the top section under Installed Integrations . Configuring the webhook in Datadog \u00b6 Go to Datadog Webhook Integration Setup Create a + New Webhook Name the webhook komodor Enter the webhook server URL in the URL field: https://app.komodor.com/collector/datadog/webhook Copy the following Payload schema into the Payload field: { \"body\" : \"$EVENT_MSG\" , \"last_updated\" : \"$LAST_UPDATED\" , \"event_type\" : \"$EVENT_TYPE\" , \"title\" : \"$EVENT_TITLE\" , \"date\" : \"$DATE\" , \"org\" : { \"id\" : \"$ORG_ID\" , \"name\" : \"$ORG_NAME\" }, \"id\" : \"$ID\" , \"tags\" : \"$TAGS\" , \"alert\" : { \"id\" : \"$ALERT_ID\" , \"type\" : \"$ALERT_TYPE\" , \"transition\" : \"$ALERT_TRANSITION\" , \"cycleId\" : \"$ALERT_CYCLE_KEY\" , \"priority\" : \"$PRIORITY\" , \"status\" : \"$ALERT_STATUS\" , \"scope\" : \"$ALERT_SCOPE\" , \"query\" : \"$ALERT_QUERY\" , \"metric\" : \"$ALERT_METRIC\" , \"metric_namespace\" : \"$METRIC_NAMESPACE\" }, \"aggregation_key\" : \"$AGGREG_KEY\" , \"link\" : \"$LINK\" , \"snapshot\" : \"$SNAPSHOT\" , \"user\" : \"$USER\" , \"username\" : \"$USERNAME\" , \"email\" : \"$EMAIL\" } Add a Custom Header X-API-KEY with the Api Key found in the Komodor Integration page from the Datadog integration tile at the bottom of the setup modal in a JSON format. { \"X-API-KEY\" : \"YOUR_KOMODOR_API_KEY\" } When completed click on Save . For every monitor you wish to receive alerts from in Komodor. Edit the monitor and add @webhook-komodor at the end of the Monitor message.","title":"Datadog Webhook"},{"location":"Integrations/datadog-webhook.html#datadog-webhook-integration","text":"Komodor-Datadog webhook integration allows Komodor to receive alerts from Datadog Monitors. You will see all alerts in the Komodor Service View.","title":"Datadog Webhook Integration"},{"location":"Integrations/datadog-webhook.html#installation","text":"","title":"Installation"},{"location":"Integrations/datadog-webhook.html#prerequisites","text":"In order for us to connect your services according to Datadog events, the following environment variables should exist on your kubernetes deployments: - DD_ENV should match the environment specified on the Datadog tags - DD_SERVICE should match the service name specified on the Datadog tags","title":"Prerequisites"},{"location":"Integrations/datadog-webhook.html#installation-steps","text":"Make sure the prerequisites above are met. Locate the Datadog installation tile on Komodor Integrations page. Press Install Integration . Follow the on screen instructions.","title":"Installation Steps"},{"location":"Integrations/datadog-webhook.html#confirmation","text":"A Datadog Integration tile will be added to the top section under Installed Integrations .","title":"Confirmation"},{"location":"Integrations/datadog-webhook.html#configuring-the-webhook-in-datadog","text":"Go to Datadog Webhook Integration Setup Create a + New Webhook Name the webhook komodor Enter the webhook server URL in the URL field: https://app.komodor.com/collector/datadog/webhook Copy the following Payload schema into the Payload field: { \"body\" : \"$EVENT_MSG\" , \"last_updated\" : \"$LAST_UPDATED\" , \"event_type\" : \"$EVENT_TYPE\" , \"title\" : \"$EVENT_TITLE\" , \"date\" : \"$DATE\" , \"org\" : { \"id\" : \"$ORG_ID\" , \"name\" : \"$ORG_NAME\" }, \"id\" : \"$ID\" , \"tags\" : \"$TAGS\" , \"alert\" : { \"id\" : \"$ALERT_ID\" , \"type\" : \"$ALERT_TYPE\" , \"transition\" : \"$ALERT_TRANSITION\" , \"cycleId\" : \"$ALERT_CYCLE_KEY\" , \"priority\" : \"$PRIORITY\" , \"status\" : \"$ALERT_STATUS\" , \"scope\" : \"$ALERT_SCOPE\" , \"query\" : \"$ALERT_QUERY\" , \"metric\" : \"$ALERT_METRIC\" , \"metric_namespace\" : \"$METRIC_NAMESPACE\" }, \"aggregation_key\" : \"$AGGREG_KEY\" , \"link\" : \"$LINK\" , \"snapshot\" : \"$SNAPSHOT\" , \"user\" : \"$USER\" , \"username\" : \"$USERNAME\" , \"email\" : \"$EMAIL\" } Add a Custom Header X-API-KEY with the Api Key found in the Komodor Integration page from the Datadog integration tile at the bottom of the setup modal in a JSON format. { \"X-API-KEY\" : \"YOUR_KOMODOR_API_KEY\" } When completed click on Save . For every monitor you wish to receive alerts from in Komodor. Edit the monitor and add @webhook-komodor at the end of the Monitor message.","title":"Configuring the webhook in Datadog"},{"location":"Learn/index.html","text":"","title":"Index"},{"location":"Learn/Annotations.html","text":"Komodor kubernetes annotations \u00b6 Komodor annotations (AKA Komodor as code), is a method to allow users to configure everything related to Komodor as part of their native k8s yaml. Komodor annotations should be placed in the deployment resource annotations (annotations set on the pod template are ignored) Notifications \u00b6 Configure the Slack channel notification as part of the deployment object. How \u00b6 Annotation Values Description Example Default app.komodor.com/notification.deploy.slack string Slack channel name for all deploy events notifications \u201cdeploy-brain-team\" app.komodor.com/notification.deploy_fail.slack string Slack channel name for failed deploy events notifications \u201cdeploy-failed\" app.komodor.com/notification.deploy_success.slack string Slack channel name for successful deploy events notifications \u201cdeploy-success\" app.komodor.com/notification.health.slack string Slack channel for health event notifications \u201calerts-p1\u201d Service Links \u00b6 Define quick-links for a specific service, making it easier to get context when troubleshooting. How \u00b6 In the form of app.komodor.com/service/link/name:url Examples: Annotation Values Description Example Default app.komodor.com/service.link.grafana-overall-system-health url Url for Grafana health dashboard related to this service. \u201cdeploy-brain-team\" app.komodor.com/service.link.datadog-http-500 url Url for datadog dashboard with bad http \u201calerts-p1\u201d app.komodor.com/service.link.company-playbook url The playbook for the company playbook \u201c120\u201d \u201c30\u201d CI-Deploy Links \u00b6 For each deployment version, you can add a quick link with the job url. How \u00b6 app.komodor.com/deploy/job/name:url Example: Annotation Values Description Example app.komodor.com/deploy.job.jenkins url Link to Jenkins job that deploys the service https://ci.jenkins-ci.org/computer/job Deploy Links \u00b6 For each deployment version, you can add a quick link with the relevant filters already in place! How \u00b6 app.komodor.com/deploy/link/name:url Examples: Annotation Values Description Example app.komodor.com/deploy.link.logs url Link for the specific version logs https://app.logz.io/#/dashboard/kibana/discover?_a=env:123.0.1 app.komodor.com/deploy.link.sentry url Link for the specific version Sentry issues https://sentry.io/organizations/rookoutz/issues/?project=1320440&query=sdk.version%3A1.0.1&statsPeriod=14d Custom Links \u00b6 You can create custom links to external and internal applications by crafting your own URL to the appplication using a skeleton URL and placeholders provided by Komodor. Just copy the URL of the application you want to link to, identify the placeholders in the URL that are used to query the appplication, and replace them with placeholders for your own use. Please find the below examples as references for common applications. How \u00b6 app.komodor.com/deploy/link/name:value Examples: Annotation Values Description Example app.komodor.com/deploy.link.coralogix url Link for the custom URL, coralogix https://komodortest.coralogix.com/#/query-new/logs?query=(coralogix.metadata.cluster:(%22${cluster}%22))%20AND%20(coralogix.metadata.namespace:(%22${namespace}%22))%20AND%20(coralogix.metadata.service:(%22${service}%22))&time=from:${timestampStart=YYYY-MM-DDTHH:mm:ss.SSSZ},to:${timestampEnd=YYYY-MM-DDTHH:mm:ss.SSSZ} app.komodor.com/deploy.link.logzio url Link for the custom URL, logz.io https://app.logz.io/#/dashboard/kibana/discover?_a=(columns:!(message,kubernetes.namespace_name,kubernetes.container_name,params.clusterName),filters:!(('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:kubernetes.namespace_name,negate:!f,params:(query:default),type:phrase),query:(match_phrase:(kubernetes.namespace_name:${namespace}))),('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:params.clusterName,negate:!f,params:(query:main),type:phrase),query:(match_phrase:(params.clusterName:${cluster}))),('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:kubernetes.container_name,negate:!f,params:(query:k8s-events-collector),type:phrase),query:(match_phrase:(kubernetes.container_name:${service})),query:(match_phrase:(kubernetes.container_image:${container[web].image})))),index:'logzioCustomerIndex',interval:auto,query:(language:lucene,query:''),sort:!(!('@timestamp',desc)))&_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:'${timestempStart=yyyy-MM-dd'T'HH:mm:ss.SSS}',to:'${timestempStart=yyyy-MM-dd'T'HH:mm:ss.SSS}'))&discoverTab=logz-logs-tab&switchToAccountId=138828&accountIds=true app.komodor.com/deploy.link.datadog url Link for the custom URL, DataDog https://app.datadoghq.com/apm/traces?query=service%3A${service}%20kube_namespace%3A${namespace}%20env%3A${cluster}&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&historicalData=true&messageDisplay=inline&sort=desc&streamTraces=true&start=${epochStart}&end=${epochEnd}&paused=true The following values can be used to enrich the URL: Placeholder Value Example ${epochStart} Start Time in Epoch Time ${epochEnd} End Time in Epoch Time ${service} Service Name ${namespace} Namespace Name ${cluster} Cluster Name ${container[<name>].image} Image name of a container ${container[web].image} ${timestempStart=yyyy-MM-dd'T'HH:mm:ss.SSS} Start Time in custom format* ${timestempStart=yyyy-MM-dd} ${timestempEnd=yyyy-MM-dd'T'HH:mm:ss.SSS} End Time in custom format* ${timestempEnd=yyyy-MM-dd} ${yaml[<spec_path>]} Full yaml's path specification ${yaml[metadata.labels.app]} Example on how to use yaml full path: spec : replicas : 5 selector : matchLabels : app : nginx template : spec : containers : - name : test image : nginx:1.14.2 ports : - containerPort : 80 - name : test2 image : nginx:1.14.2 ports : - containerPort : 80 Yaml Path Value Explanation {$yaml[spec.replicas]} 5 full path usage {$yaml[spec.template.spec.containers[0].name]} test full path usage using path index {$yaml[spec.my_replicas]} undefined path doesn't exist {$yaml[spec.tamplate.spec.containers]} undefined path doesn't resolve to an actual value *Dates can be crasfted using the display guidelines of date-fns https://date-fns.org/v2.25.0/docs/format Full example \u00b6 apiVersion : apps/v1 kind : Deployment metadata : name : annotation-example annotations : app.komodor.com/notification.deploy.slack : \"#deploy-slack-channel\" app.komodor.com/service.link.grafana-overall-system-health : \"https://grafana.com/service/annoation-exmaple\" app.komodor.com/service.link.datadog : \"https://datadog.com/dashboard/annoation-exmaple\" app.komodor.com/service.link.playbook : \"https://docs.google.com/playbook\" app.komodor.com/deploy.job.jenkins : \"https://ci.jenkins-ci.org/computer/job\" app.komodor.com/deploy.link.logs : \"https://app.logz.io/#/dashboard/kibana/discover?_a=env:1.0.1\" app.komodor.com/deploy.link.sentry : \"https://sentry.io/organizations/rookoutz/issues/?project=1320440&query=sdk.version%3A1.0.1&statsPeriod=14d\" app.komodor.com/service.link.datadog : \"https://app.datadoghq.com/apm/traces?query=service%3A${service}%20kube_namespace%3A${namespace}%20env%3A${cluster}&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&historicalData=true&messageDisplay=inline&sort=desc&streamTraces=true&start=${epochStart}&end=${epochEnd}&paused=true\" spec : selector : matchLabels : run : example replicas : 1 template : metadata : labels : run : example spec : containers : - name : hello-world image : gcr.io/google-samples/node-hello:1.0.1 ports : - containerPort : 8080 protocol : TCP Annotations Best Practices \u00b6 At Komodor we believe that k8s annotations are the best method for describing services metadata. This includes all the \u201cextra\u201d fields used to tag and label your services, both for other team members and for external tools. BTW, We collect data from both annotations and labels. Where does Komodor utilize annotations? \u00b6 Everywhere! Komodor will use these annotations to create powerful connections between services and enrich service information in the following areas: Services explorer Related services Events screen Matching alerts to the correct services Official Kubernetes recommendations \u00b6 app.kubernetes.io/component : database app.kubernetes.io/part-of : wordpress app.kubernetes.io/managed-by : helm Komodor recommendations \u00b6 app.komodor.com/label.team : backend app.komodor.com/label.group : infrastructure app.komodor.com/label.owners : \"#infa-team\" app.komodor.com/label.alert-team : \"#devs\" app.komodor.com/label.Impacted-by : redis Usage example \u00b6 Tagging Team annotations on relevant services and adding relevant metadata on the alert metadata in datadog. Using the Team name in the alert tools (for example PagerDuty) as part of the Komodor labels.","title":"Annotations"},{"location":"Learn/Annotations.html#komodor-kubernetes-annotations","text":"Komodor annotations (AKA Komodor as code), is a method to allow users to configure everything related to Komodor as part of their native k8s yaml. Komodor annotations should be placed in the deployment resource annotations (annotations set on the pod template are ignored)","title":"Komodor kubernetes annotations"},{"location":"Learn/Annotations.html#notifications","text":"Configure the Slack channel notification as part of the deployment object.","title":"Notifications"},{"location":"Learn/Annotations.html#how","text":"Annotation Values Description Example Default app.komodor.com/notification.deploy.slack string Slack channel name for all deploy events notifications \u201cdeploy-brain-team\" app.komodor.com/notification.deploy_fail.slack string Slack channel name for failed deploy events notifications \u201cdeploy-failed\" app.komodor.com/notification.deploy_success.slack string Slack channel name for successful deploy events notifications \u201cdeploy-success\" app.komodor.com/notification.health.slack string Slack channel for health event notifications \u201calerts-p1\u201d","title":"How"},{"location":"Learn/Annotations.html#service-links","text":"Define quick-links for a specific service, making it easier to get context when troubleshooting.","title":"Service Links"},{"location":"Learn/Annotations.html#how_1","text":"In the form of app.komodor.com/service/link/name:url Examples: Annotation Values Description Example Default app.komodor.com/service.link.grafana-overall-system-health url Url for Grafana health dashboard related to this service. \u201cdeploy-brain-team\" app.komodor.com/service.link.datadog-http-500 url Url for datadog dashboard with bad http \u201calerts-p1\u201d app.komodor.com/service.link.company-playbook url The playbook for the company playbook \u201c120\u201d \u201c30\u201d","title":"How"},{"location":"Learn/Annotations.html#ci-deploy-links","text":"For each deployment version, you can add a quick link with the job url.","title":"CI-Deploy Links"},{"location":"Learn/Annotations.html#how_2","text":"app.komodor.com/deploy/job/name:url Example: Annotation Values Description Example app.komodor.com/deploy.job.jenkins url Link to Jenkins job that deploys the service https://ci.jenkins-ci.org/computer/job","title":"How"},{"location":"Learn/Annotations.html#deploy-links","text":"For each deployment version, you can add a quick link with the relevant filters already in place!","title":"Deploy Links"},{"location":"Learn/Annotations.html#how_3","text":"app.komodor.com/deploy/link/name:url Examples: Annotation Values Description Example app.komodor.com/deploy.link.logs url Link for the specific version logs https://app.logz.io/#/dashboard/kibana/discover?_a=env:123.0.1 app.komodor.com/deploy.link.sentry url Link for the specific version Sentry issues https://sentry.io/organizations/rookoutz/issues/?project=1320440&query=sdk.version%3A1.0.1&statsPeriod=14d","title":"How"},{"location":"Learn/Annotations.html#custom-links","text":"You can create custom links to external and internal applications by crafting your own URL to the appplication using a skeleton URL and placeholders provided by Komodor. Just copy the URL of the application you want to link to, identify the placeholders in the URL that are used to query the appplication, and replace them with placeholders for your own use. Please find the below examples as references for common applications.","title":"Custom Links"},{"location":"Learn/Annotations.html#how_4","text":"app.komodor.com/deploy/link/name:value Examples: Annotation Values Description Example app.komodor.com/deploy.link.coralogix url Link for the custom URL, coralogix https://komodortest.coralogix.com/#/query-new/logs?query=(coralogix.metadata.cluster:(%22${cluster}%22))%20AND%20(coralogix.metadata.namespace:(%22${namespace}%22))%20AND%20(coralogix.metadata.service:(%22${service}%22))&time=from:${timestampStart=YYYY-MM-DDTHH:mm:ss.SSSZ},to:${timestampEnd=YYYY-MM-DDTHH:mm:ss.SSSZ} app.komodor.com/deploy.link.logzio url Link for the custom URL, logz.io https://app.logz.io/#/dashboard/kibana/discover?_a=(columns:!(message,kubernetes.namespace_name,kubernetes.container_name,params.clusterName),filters:!(('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:kubernetes.namespace_name,negate:!f,params:(query:default),type:phrase),query:(match_phrase:(kubernetes.namespace_name:${namespace}))),('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:params.clusterName,negate:!f,params:(query:main),type:phrase),query:(match_phrase:(params.clusterName:${cluster}))),('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:kubernetes.container_name,negate:!f,params:(query:k8s-events-collector),type:phrase),query:(match_phrase:(kubernetes.container_name:${service})),query:(match_phrase:(kubernetes.container_image:${container[web].image})))),index:'logzioCustomerIndex',interval:auto,query:(language:lucene,query:''),sort:!(!('@timestamp',desc)))&_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:'${timestempStart=yyyy-MM-dd'T'HH:mm:ss.SSS}',to:'${timestempStart=yyyy-MM-dd'T'HH:mm:ss.SSS}'))&discoverTab=logz-logs-tab&switchToAccountId=138828&accountIds=true app.komodor.com/deploy.link.datadog url Link for the custom URL, DataDog https://app.datadoghq.com/apm/traces?query=service%3A${service}%20kube_namespace%3A${namespace}%20env%3A${cluster}&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&historicalData=true&messageDisplay=inline&sort=desc&streamTraces=true&start=${epochStart}&end=${epochEnd}&paused=true The following values can be used to enrich the URL: Placeholder Value Example ${epochStart} Start Time in Epoch Time ${epochEnd} End Time in Epoch Time ${service} Service Name ${namespace} Namespace Name ${cluster} Cluster Name ${container[<name>].image} Image name of a container ${container[web].image} ${timestempStart=yyyy-MM-dd'T'HH:mm:ss.SSS} Start Time in custom format* ${timestempStart=yyyy-MM-dd} ${timestempEnd=yyyy-MM-dd'T'HH:mm:ss.SSS} End Time in custom format* ${timestempEnd=yyyy-MM-dd} ${yaml[<spec_path>]} Full yaml's path specification ${yaml[metadata.labels.app]} Example on how to use yaml full path: spec : replicas : 5 selector : matchLabels : app : nginx template : spec : containers : - name : test image : nginx:1.14.2 ports : - containerPort : 80 - name : test2 image : nginx:1.14.2 ports : - containerPort : 80 Yaml Path Value Explanation {$yaml[spec.replicas]} 5 full path usage {$yaml[spec.template.spec.containers[0].name]} test full path usage using path index {$yaml[spec.my_replicas]} undefined path doesn't exist {$yaml[spec.tamplate.spec.containers]} undefined path doesn't resolve to an actual value *Dates can be crasfted using the display guidelines of date-fns https://date-fns.org/v2.25.0/docs/format","title":"How"},{"location":"Learn/Annotations.html#full-example","text":"apiVersion : apps/v1 kind : Deployment metadata : name : annotation-example annotations : app.komodor.com/notification.deploy.slack : \"#deploy-slack-channel\" app.komodor.com/service.link.grafana-overall-system-health : \"https://grafana.com/service/annoation-exmaple\" app.komodor.com/service.link.datadog : \"https://datadog.com/dashboard/annoation-exmaple\" app.komodor.com/service.link.playbook : \"https://docs.google.com/playbook\" app.komodor.com/deploy.job.jenkins : \"https://ci.jenkins-ci.org/computer/job\" app.komodor.com/deploy.link.logs : \"https://app.logz.io/#/dashboard/kibana/discover?_a=env:1.0.1\" app.komodor.com/deploy.link.sentry : \"https://sentry.io/organizations/rookoutz/issues/?project=1320440&query=sdk.version%3A1.0.1&statsPeriod=14d\" app.komodor.com/service.link.datadog : \"https://app.datadoghq.com/apm/traces?query=service%3A${service}%20kube_namespace%3A${namespace}%20env%3A${cluster}&cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&historicalData=true&messageDisplay=inline&sort=desc&streamTraces=true&start=${epochStart}&end=${epochEnd}&paused=true\" spec : selector : matchLabels : run : example replicas : 1 template : metadata : labels : run : example spec : containers : - name : hello-world image : gcr.io/google-samples/node-hello:1.0.1 ports : - containerPort : 8080 protocol : TCP","title":"Full example"},{"location":"Learn/Annotations.html#annotations-best-practices","text":"At Komodor we believe that k8s annotations are the best method for describing services metadata. This includes all the \u201cextra\u201d fields used to tag and label your services, both for other team members and for external tools. BTW, We collect data from both annotations and labels.","title":"Annotations Best Practices"},{"location":"Learn/Annotations.html#where-does-komodor-utilize-annotations","text":"Everywhere! Komodor will use these annotations to create powerful connections between services and enrich service information in the following areas: Services explorer Related services Events screen Matching alerts to the correct services","title":"Where does Komodor utilize annotations?"},{"location":"Learn/Annotations.html#official-kubernetes-recommendations","text":"app.kubernetes.io/component : database app.kubernetes.io/part-of : wordpress app.kubernetes.io/managed-by : helm","title":"Official Kubernetes recommendations"},{"location":"Learn/Annotations.html#komodor-recommendations","text":"app.komodor.com/label.team : backend app.komodor.com/label.group : infrastructure app.komodor.com/label.owners : \"#infa-team\" app.komodor.com/label.alert-team : \"#devs\" app.komodor.com/label.Impacted-by : redis","title":"Komodor recommendations"},{"location":"Learn/Annotations.html#usage-example","text":"Tagging Team annotations on relevant services and adding relevant metadata on the alert metadata in datadog. Using the Team name in the alert tools (for example PagerDuty) as part of the Komodor labels.","title":"Usage example"},{"location":"Learn/Interaction-With-The-Cluster.html","text":"Interaction with the Cluster \u00b6 Interaction with the cluster allows you to speed up the troubleshooting process. This is done by asking Komodor's agent to perform actions in the cluster. Prerequisites \u00b6 Install Komodor's watcher (version >=0.1.44 ) --set watcher.enableAgentTaskExecution=true to start the agent with the feature turned on (required for Describe Action ) Extra Permissions Required \u00b6 In order to get logs from the cluster please use --set watcher.allowReadingPodLogs=true to update the RBAC manifests with the required permissions (required for Pod Log Action ) You can turn any of these flags off at any time to disable the features Upgrade \u00b6 helm repo update helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.enableAgentTaskExecution = true --set watcher.allowReadingPodLogs = true --reuse-values Live Pods \u00b6 In the service, click on the Pod Status and Logs button. The table shows all the pods that belong to the service based on the pod owner controller. Actions \u00b6 Pod Logs \u00b6 Request logs from one of the pods will stream back the last 100 logs from the pod. When a pod was previously restarted by Kubernetes you can see the logs just before the pod was restarted. Pod Description \u00b6 Request returns the same output as kubectl describe pod [NAME]","title":"Interaction with the Cluster"},{"location":"Learn/Interaction-With-The-Cluster.html#interaction-with-the-cluster","text":"Interaction with the cluster allows you to speed up the troubleshooting process. This is done by asking Komodor's agent to perform actions in the cluster.","title":"Interaction with the Cluster"},{"location":"Learn/Interaction-With-The-Cluster.html#prerequisites","text":"Install Komodor's watcher (version >=0.1.44 ) --set watcher.enableAgentTaskExecution=true to start the agent with the feature turned on (required for Describe Action )","title":"Prerequisites"},{"location":"Learn/Interaction-With-The-Cluster.html#extra-permissions-required","text":"In order to get logs from the cluster please use --set watcher.allowReadingPodLogs=true to update the RBAC manifests with the required permissions (required for Pod Log Action ) You can turn any of these flags off at any time to disable the features","title":"Extra Permissions Required"},{"location":"Learn/Interaction-With-The-Cluster.html#upgrade","text":"helm repo update helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.enableAgentTaskExecution = true --set watcher.allowReadingPodLogs = true --reuse-values","title":"Upgrade"},{"location":"Learn/Interaction-With-The-Cluster.html#live-pods","text":"In the service, click on the Pod Status and Logs button. The table shows all the pods that belong to the service based on the pod owner controller.","title":"Live Pods"},{"location":"Learn/Interaction-With-The-Cluster.html#actions","text":"","title":"Actions"},{"location":"Learn/Interaction-With-The-Cluster.html#pod-logs","text":"Request logs from one of the pods will stream back the last 100 logs from the pod. When a pod was previously restarted by Kubernetes you can see the logs just before the pod was restarted.","title":"Pod Logs"},{"location":"Learn/Interaction-With-The-Cluster.html#pod-description","text":"Request returns the same output as kubectl describe pod [NAME]","title":"Pod Description"},{"location":"Learn/Komodor-Agent.html","text":"The Komodor Agent \u00b6 Installation \u00b6 Get an API Key \u00b6 The API key can be found in the Integration page . Helm \u00b6 helm repo add komodorio https://helm-charts.komodor.io helm repo update helm upgrade --install k8s-watcher komodorio/k8s-watcher \\ --set apiKey = YOUR_API_KEY_HERE \\ --set watcher.clusterName = CLUSTER_NAME \\ --set watcher.enableAgentTaskExecution = true \\ --set watcher.allowReadingPodLogs = true Kustomize \u00b6 export KOMOKW_API_KEY = # API KEY Required export KOMOKW_CLUSTER_NAME = # Optional kubectl create ns komodor kubectl apply -n komodor -k https://github.com/komodorio/helm-charts/manifests/overlays/full/?ref = master Permissions \u00b6 The Komodor agent uses the native RBAC model of Kubernetes. All the permissions are listed here: helm kustomize base , kustomize final ARM Support \u00b6 Arm64 image is supported via docker manifest. Advanced Configuration \u00b6 You can configure the agent's functionality using the following configuration file: komodor-k8s-watcher.yaml (assuming the RBAC permissions are satisfied). A more detailed list of the configurable parameters can be found here Data Redaction \u00b6 Learn how to set up data redaction in Komodor Resources \u00b6 By default, the Komodor agent watches the majority of the resources in your cluster ( secrets and events are opt out ) You can enable/disable watching a resource using the following command: Helm: --set watcher.resources.RESOURCE=true/off Kustomize: update the configuration file and the RBAC rule to have get , list and watch permissions Namespaces \u00b6 The Komodor agent watches all the namespaces (by default watchNamespace=all ) To watch a single namespace use the following command: Helm: --set watcher.watchNamespace=NAMESPACE Kustomize: patch the configuration file watchNamespace=NAMESPACE Blacklisting \u00b6 Using namespacesBlacklist you can opt list of namespaces Agent Tasks \u00b6 Agent tasks are used to interact with the cluster on demand, read more about interaction with the cluster here To enable agent tasks (default is off ): Helm: --set watcher.enableAgentTaskExecution=true && --set watcher.allowReadingPodLogs=true Kustomize: The full overlay already has this turned on. If you are building it manually from base , patch the configuration file enableAgentTaskExecution=true and make sure to have RBAC permissions to get and list for pods and pods/log Environment Variables \u00b6 Alternativly, you can pass the configuration as environment variables using the KOMOKW_ prefix and by replacing all the . to _, for the root items the camelcase transforms into underscores as well. For example: # apiKey KOMOKW_API_KEY = 1a2b3c4d5e6f7g7h # watcher.resources.replicaSet KOMOKW_RESOURCES_REPLICASET = false # watcher.watchNamespace KOMOKW_WATCH_NAMESPACE = my-namespace # watcher.collectHistory KOMOKW_COLLECT_HISTORY = true Updating the agent \u00b6 Kustomize \u00b6 kubectl apply -n komodor -k https://github.com/komodorio/helm-charts/manifests/overlays/full/?ref = master Helm \u00b6 helm repo update helm upgrade --install k8s-watcher komodorio/k8s-watcher --reuse-values Uninstalling \u00b6 Kustomize \u00b6 kubectl delete ns komodor Helm \u00b6 helm uninstall k8s-watcher","title":"Komodor's Agent"},{"location":"Learn/Komodor-Agent.html#the-komodor-agent","text":"","title":"The Komodor Agent"},{"location":"Learn/Komodor-Agent.html#installation","text":"","title":"Installation"},{"location":"Learn/Komodor-Agent.html#get-an-api-key","text":"The API key can be found in the Integration page .","title":"Get an API Key"},{"location":"Learn/Komodor-Agent.html#helm","text":"helm repo add komodorio https://helm-charts.komodor.io helm repo update helm upgrade --install k8s-watcher komodorio/k8s-watcher \\ --set apiKey = YOUR_API_KEY_HERE \\ --set watcher.clusterName = CLUSTER_NAME \\ --set watcher.enableAgentTaskExecution = true \\ --set watcher.allowReadingPodLogs = true","title":"Helm"},{"location":"Learn/Komodor-Agent.html#kustomize","text":"export KOMOKW_API_KEY = # API KEY Required export KOMOKW_CLUSTER_NAME = # Optional kubectl create ns komodor kubectl apply -n komodor -k https://github.com/komodorio/helm-charts/manifests/overlays/full/?ref = master","title":"Kustomize"},{"location":"Learn/Komodor-Agent.html#permissions","text":"The Komodor agent uses the native RBAC model of Kubernetes. All the permissions are listed here: helm kustomize base , kustomize final","title":"Permissions"},{"location":"Learn/Komodor-Agent.html#arm-support","text":"Arm64 image is supported via docker manifest.","title":"ARM Support"},{"location":"Learn/Komodor-Agent.html#advanced-configuration","text":"You can configure the agent's functionality using the following configuration file: komodor-k8s-watcher.yaml (assuming the RBAC permissions are satisfied). A more detailed list of the configurable parameters can be found here","title":"Advanced Configuration"},{"location":"Learn/Komodor-Agent.html#data-redaction","text":"Learn how to set up data redaction in Komodor","title":"Data Redaction"},{"location":"Learn/Komodor-Agent.html#resources","text":"By default, the Komodor agent watches the majority of the resources in your cluster ( secrets and events are opt out ) You can enable/disable watching a resource using the following command: Helm: --set watcher.resources.RESOURCE=true/off Kustomize: update the configuration file and the RBAC rule to have get , list and watch permissions","title":"Resources"},{"location":"Learn/Komodor-Agent.html#namespaces","text":"The Komodor agent watches all the namespaces (by default watchNamespace=all ) To watch a single namespace use the following command: Helm: --set watcher.watchNamespace=NAMESPACE Kustomize: patch the configuration file watchNamespace=NAMESPACE","title":"Namespaces"},{"location":"Learn/Komodor-Agent.html#blacklisting","text":"Using namespacesBlacklist you can opt list of namespaces","title":"Blacklisting"},{"location":"Learn/Komodor-Agent.html#agent-tasks","text":"Agent tasks are used to interact with the cluster on demand, read more about interaction with the cluster here To enable agent tasks (default is off ): Helm: --set watcher.enableAgentTaskExecution=true && --set watcher.allowReadingPodLogs=true Kustomize: The full overlay already has this turned on. If you are building it manually from base , patch the configuration file enableAgentTaskExecution=true and make sure to have RBAC permissions to get and list for pods and pods/log","title":"Agent Tasks"},{"location":"Learn/Komodor-Agent.html#environment-variables","text":"Alternativly, you can pass the configuration as environment variables using the KOMOKW_ prefix and by replacing all the . to _, for the root items the camelcase transforms into underscores as well. For example: # apiKey KOMOKW_API_KEY = 1a2b3c4d5e6f7g7h # watcher.resources.replicaSet KOMOKW_RESOURCES_REPLICASET = false # watcher.watchNamespace KOMOKW_WATCH_NAMESPACE = my-namespace # watcher.collectHistory KOMOKW_COLLECT_HISTORY = true","title":"Environment Variables"},{"location":"Learn/Komodor-Agent.html#updating-the-agent","text":"","title":"Updating the agent"},{"location":"Learn/Komodor-Agent.html#kustomize_1","text":"kubectl apply -n komodor -k https://github.com/komodorio/helm-charts/manifests/overlays/full/?ref = master","title":"Kustomize"},{"location":"Learn/Komodor-Agent.html#helm_1","text":"helm repo update helm upgrade --install k8s-watcher komodorio/k8s-watcher --reuse-values","title":"Helm"},{"location":"Learn/Komodor-Agent.html#uninstalling","text":"","title":"Uninstalling"},{"location":"Learn/Komodor-Agent.html#kustomize_2","text":"kubectl delete ns komodor","title":"Kustomize"},{"location":"Learn/Komodor-Agent.html#helm_2","text":"helm uninstall k8s-watcher","title":"Helm"},{"location":"Learn/RBAC.html","text":"Role-Based Access Control \u00b6 Intro \u00b6 Roles categorize users and define what permissions those users have, such as what data they can read or what they can modify. Komodor Roles: \u00b6 Permissions Admin User View all features \u2713 \u2713 Invite Admin member \u2713 \u2718 Invite User member \u2713 \u2713 Add a new integration \u2713 \u2718 See API keys in the Integrations page \u2713 \u2718 Note An account can have multiple admins","title":"RBAC"},{"location":"Learn/RBAC.html#role-based-access-control","text":"","title":"Role-Based Access Control"},{"location":"Learn/RBAC.html#intro","text":"Roles categorize users and define what permissions those users have, such as what data they can read or what they can modify.","title":"Intro"},{"location":"Learn/RBAC.html#komodor-roles","text":"Permissions Admin User View all features \u2713 \u2713 Invite Admin member \u2713 \u2718 Invite User member \u2713 \u2713 Add a new integration \u2713 \u2718 See API keys in the Integrations page \u2713 \u2718 Note An account can have multiple admins","title":"Komodor Roles:"},{"location":"Learn/Sensitive-Information-Redaction.html","text":"Sensitive data redaction in Komodor\u2019s k8s-watcher \u00b6 What is it \u00b6 It\u2019s likely that there are values you don\u2019t want to send to Komodor as plain text. Kubernetes Secrets, for instance, ConfigMap sensitive values or container environment variables. When configured - we will redact the specific value. That way Komodor won't see any sensitive data while you will still see configuration diff. How to integrate \u00b6 Inside komodor-k8s-watcher.yaml you should add a list of string or regular expressions under redact key as such: komodor-k8s-watcher watchNamespace : all namespacesBlacklist : - kube-system redact : - \"PG_.*\" - \".*PASSWORD.*\" nameBlacklist : [ \"leader\" , \"election\" ] collectHistory : false Secret Resource \u00b6 By default, Komodor\u2019s k8s-watcher is hashing all secrets values. ConfigMap resource \u00b6 You can preconfigure a list of keys for Kubernetes watcher to also redact specific values from ConfigMap. komodor-k8s-watcher.yaml: redact : - \"SENTRY_API_KEY\" - \"PG_.*\" configmap.yaml: apiVersion : v1 kind : ConfigMap metadata : Name : sensitive-config-map data : SENTRY_API_KEY : super_secret PG_SECRET : super_secret PG_USERNAME : super_secret All the above \u201csuper_secret\u201d will be sent has hashed value. Deployment resource \u00b6 Komodor\u2019s k8s-watcher will hash template.spec.template.[containeres|initContainers].env list of variables inside Deployment objects for pre-configured list of keys or list of regular expressions. komodor-k8s-watcher.yaml: redact : - \"SENTRY_API_KEY\" - \"PG_.*\" deployment.yaml: apiVersion : apps/v1 kind : Deployment metadata : name : sensitive-deployment spec : selector : matchLabels : run : example replicas : 1 template : metadata : labels : run : example spec : containers : - name : hello-world image : gcr.io/google-samples/node-hello:1.0 env : - name : PG_USERNAME value : super_secret - name : SECRET value : this_will_show_up In the above deployment example we will not send the secret values for PG_USERNAME. SECRET will show up as is due to the fact it won\u2019t match any string or regex in our configuration.","title":"Sensitive Information Redaction"},{"location":"Learn/Sensitive-Information-Redaction.html#sensitive-data-redaction-in-komodors-k8s-watcher","text":"","title":"Sensitive data redaction in Komodor\u2019s k8s-watcher"},{"location":"Learn/Sensitive-Information-Redaction.html#what-is-it","text":"It\u2019s likely that there are values you don\u2019t want to send to Komodor as plain text. Kubernetes Secrets, for instance, ConfigMap sensitive values or container environment variables. When configured - we will redact the specific value. That way Komodor won't see any sensitive data while you will still see configuration diff.","title":"What is it"},{"location":"Learn/Sensitive-Information-Redaction.html#how-to-integrate","text":"Inside komodor-k8s-watcher.yaml you should add a list of string or regular expressions under redact key as such: komodor-k8s-watcher watchNamespace : all namespacesBlacklist : - kube-system redact : - \"PG_.*\" - \".*PASSWORD.*\" nameBlacklist : [ \"leader\" , \"election\" ] collectHistory : false","title":"How to integrate"},{"location":"Learn/Sensitive-Information-Redaction.html#secret-resource","text":"By default, Komodor\u2019s k8s-watcher is hashing all secrets values.","title":"Secret Resource"},{"location":"Learn/Sensitive-Information-Redaction.html#configmap-resource","text":"You can preconfigure a list of keys for Kubernetes watcher to also redact specific values from ConfigMap. komodor-k8s-watcher.yaml: redact : - \"SENTRY_API_KEY\" - \"PG_.*\" configmap.yaml: apiVersion : v1 kind : ConfigMap metadata : Name : sensitive-config-map data : SENTRY_API_KEY : super_secret PG_SECRET : super_secret PG_USERNAME : super_secret All the above \u201csuper_secret\u201d will be sent has hashed value.","title":"ConfigMap resource"},{"location":"Learn/Sensitive-Information-Redaction.html#deployment-resource","text":"Komodor\u2019s k8s-watcher will hash template.spec.template.[containeres|initContainers].env list of variables inside Deployment objects for pre-configured list of keys or list of regular expressions. komodor-k8s-watcher.yaml: redact : - \"SENTRY_API_KEY\" - \"PG_.*\" deployment.yaml: apiVersion : apps/v1 kind : Deployment metadata : name : sensitive-deployment spec : selector : matchLabels : run : example replicas : 1 template : metadata : labels : run : example spec : containers : - name : hello-world image : gcr.io/google-samples/node-hello:1.0 env : - name : PG_USERNAME value : super_secret - name : SECRET value : this_will_show_up In the above deployment example we will not send the secret values for PG_USERNAME. SECRET will show up as is due to the fact it won\u2019t match any string or regex in our configuration.","title":"Deployment resource"},{"location":"Learn/config-changes.html","text":"Config Change API Integration \u00b6 Config change API allows users to send changes in their config (from internal tools and infrastructure), and see them as part of the Komodor Service view. How to use \u00b6 Request URL \u00b6 Mandatory query params will be used for service selection: serviceName namespace clusterName URL example https://api.komodor.com/v0/config_change?serviceName=backend-service&namespace=default&clusterName=production\" Authentication \u00b6 To authenticate the request use API Key on your \"REST API\" integration tile in the Komodor app and add it to a header with X-API-KEY name. The REST API key can be found in the Integration page . If REST API integration isn't available for your account, please contact your account manager in Komodor. Body \u00b6 This is the event itself with the relevant configuration you want to be connected to the service as JSON. { key1: value1, key2: value2\u2026 } Config map and Secrets \u00b6 Configmap and Secrets can be shown in events tab, please contact us if you want this option. Configmaps that include the coming words will be ignored: \"istio\" \"cluster-autoscaler-status\" Full Example \u00b6 curl -H \"X-API-KEY: <rest api key>\" -H \"Content-Type: application/json\" -d '{\"key\":\"value\"}' \"https://api.komodor.com/v0/config_change?serviceName=backend-service&namespace=default&clusterName=production\"","title":"Config Changes"},{"location":"Learn/config-changes.html#config-change-api-integration","text":"Config change API allows users to send changes in their config (from internal tools and infrastructure), and see them as part of the Komodor Service view.","title":"Config Change API Integration"},{"location":"Learn/config-changes.html#how-to-use","text":"","title":"How to use"},{"location":"Learn/config-changes.html#request-url","text":"Mandatory query params will be used for service selection: serviceName namespace clusterName URL example https://api.komodor.com/v0/config_change?serviceName=backend-service&namespace=default&clusterName=production\"","title":"Request URL"},{"location":"Learn/config-changes.html#authentication","text":"To authenticate the request use API Key on your \"REST API\" integration tile in the Komodor app and add it to a header with X-API-KEY name. The REST API key can be found in the Integration page . If REST API integration isn't available for your account, please contact your account manager in Komodor.","title":"Authentication"},{"location":"Learn/config-changes.html#body","text":"This is the event itself with the relevant configuration you want to be connected to the service as JSON. { key1: value1, key2: value2\u2026 }","title":"Body"},{"location":"Learn/config-changes.html#config-map-and-secrets","text":"Configmap and Secrets can be shown in events tab, please contact us if you want this option. Configmaps that include the coming words will be ignored: \"istio\" \"cluster-autoscaler-status\"","title":"Config map and Secrets"},{"location":"Learn/config-changes.html#full-example","text":"curl -H \"X-API-KEY: <rest api key>\" -H \"Content-Type: application/json\" -d '{\"key\":\"value\"}' \"https://api.komodor.com/v0/config_change?serviceName=backend-service&namespace=default&clusterName=production\"","title":"Full Example"},{"location":"Learn/komodor-source-control.html","text":"Komodor source control support \u00b6 What is it \u00b6 Enrich services with relevant source control metadata. This allows to show smart-diffs as part of Komodor service changes tracking. Doing so connects the specific service with repositories that might not be the original codebase, such as infrastructure or CI repos, which are still relevant changes. How to integrate \u00b6 Add the following annotations to your service's Kubernetes spec: app.komodor.com/[name] : FULL_REPO_URL app.komodor.com/[name].ref : SOURCE_CONTROL_REF app.komodor.com/[another-name] : ANOTHER_FULL_REPO_URL app.komodor.com/[another-name].ref : ANOTHER_ SOURCE_CONTROL_REF Full example \u00b6 apiVersion : apps/v1 kind : Deployment metadata : name : git-example annotations : app.komodor.com/app : https://github.com/komodorio/infra app.komodor.com/app.ref : 3350e3311f9520fe5e237e2d71f339029ee051d8 app.komodor.com/infra : https://github.com/komodorio/helm-charts app.komodor.com/infra.ref : 32b355df32713afc511528d909eff296e91dbe74 spec : selector : matchLabels : run : example replicas : 1 template : metadata : labels : run : example spec : containers : - name : hello-world image : gcr.io/google-samples/node-hello:1.0 ports : - containerPort : 8080 protocol : TCP Microsoft DevOps Pipelines Example \u00b6 Microsoft DevOps Pipelines provides predefined variables that contains all the data needed to configure the source control annotations. Modify your pipeline to use these variables when templating the Kubernetes manifests. annotations : app.komodor.com/app : $(Build.Repository.Uri) app.komodor.com/app.ref : $(Build.SourceVersion) Tracked Files \u00b6 Once the integration with Github is established, Komodor will scan the pull requests files (only the names), to see if there are common, interesting files that have been updated. For example, when there was a change in Dockerfile , Komodor will show that in the Deploy summary. To customize which files will be tracked by Komodor. Using Kubernetes annotation app.komodor.com/tracked_files that accepts multiline string (gitignore like) to specify the files. For example, track any yaml files: apiVersion : apps/v1 kind : Deployment metadata : name : git-example annotations : app.komodor.com/tracked_files : | *.yaml app.komodor.com/app : https://github.com/komodorio/infra app.komodor.com/app.ref : 3350e3311f9520fe5e237e2d71f339029ee051d8 app.komodor.com/infra : https://github.com/komodorio/helm-charts app.komodor.com/infra.ref : 32b355df32713afc511528d909eff296e91dbe74 spec : selector : matchLabels : run : example replicas : 1 template : metadata : labels : run : example spec : containers : - name : hello-world image : gcr.io/google-samples/node-hello:1.0 ports : - containerPort : 8080 protocol : TCP\"","title":"Source Control"},{"location":"Learn/komodor-source-control.html#komodor-source-control-support","text":"","title":"Komodor source control support"},{"location":"Learn/komodor-source-control.html#what-is-it","text":"Enrich services with relevant source control metadata. This allows to show smart-diffs as part of Komodor service changes tracking. Doing so connects the specific service with repositories that might not be the original codebase, such as infrastructure or CI repos, which are still relevant changes.","title":"What is it"},{"location":"Learn/komodor-source-control.html#how-to-integrate","text":"Add the following annotations to your service's Kubernetes spec: app.komodor.com/[name] : FULL_REPO_URL app.komodor.com/[name].ref : SOURCE_CONTROL_REF app.komodor.com/[another-name] : ANOTHER_FULL_REPO_URL app.komodor.com/[another-name].ref : ANOTHER_ SOURCE_CONTROL_REF","title":"How to integrate"},{"location":"Learn/komodor-source-control.html#full-example","text":"apiVersion : apps/v1 kind : Deployment metadata : name : git-example annotations : app.komodor.com/app : https://github.com/komodorio/infra app.komodor.com/app.ref : 3350e3311f9520fe5e237e2d71f339029ee051d8 app.komodor.com/infra : https://github.com/komodorio/helm-charts app.komodor.com/infra.ref : 32b355df32713afc511528d909eff296e91dbe74 spec : selector : matchLabels : run : example replicas : 1 template : metadata : labels : run : example spec : containers : - name : hello-world image : gcr.io/google-samples/node-hello:1.0 ports : - containerPort : 8080 protocol : TCP","title":"Full example"},{"location":"Learn/komodor-source-control.html#microsoft-devops-pipelines-example","text":"Microsoft DevOps Pipelines provides predefined variables that contains all the data needed to configure the source control annotations. Modify your pipeline to use these variables when templating the Kubernetes manifests. annotations : app.komodor.com/app : $(Build.Repository.Uri) app.komodor.com/app.ref : $(Build.SourceVersion)","title":"Microsoft DevOps Pipelines Example"},{"location":"Learn/komodor-source-control.html#tracked-files","text":"Once the integration with Github is established, Komodor will scan the pull requests files (only the names), to see if there are common, interesting files that have been updated. For example, when there was a change in Dockerfile , Komodor will show that in the Deploy summary. To customize which files will be tracked by Komodor. Using Kubernetes annotation app.komodor.com/tracked_files that accepts multiline string (gitignore like) to specify the files. For example, track any yaml files: apiVersion : apps/v1 kind : Deployment metadata : name : git-example annotations : app.komodor.com/tracked_files : | *.yaml app.komodor.com/app : https://github.com/komodorio/infra app.komodor.com/app.ref : 3350e3311f9520fe5e237e2d71f339029ee051d8 app.komodor.com/infra : https://github.com/komodorio/helm-charts app.komodor.com/infra.ref : 32b355df32713afc511528d909eff296e91dbe74 spec : selector : matchLabels : run : example replicas : 1 template : metadata : labels : run : example spec : containers : - name : hello-world image : gcr.io/google-samples/node-hello:1.0 ports : - containerPort : 8080 protocol : TCP\"","title":"Tracked Files"}]}